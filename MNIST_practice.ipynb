{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "\n",
    "some_digit = X[2600]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap=mpl.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetasujmy również zbiór danych uczących; dzięki temu mamy pewność, że podzbiory utworzone\n",
    "podczas sprawdzianu krzyżowego będą do siebie podobne (nie chcemy, aby w którymś podzbiorze\n",
    "zabrakło jakiejś cyfry). Ponadto niektóre algorytmy są wrażliwe na kolejność próbek uczących i nie\n",
    "za dobrze sobie radzą, jeżeli przetwarzają wiele podobnych przykładów z rzędu. Unikniemy tego problemu dzięki przetasowaniu zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(60000)\n",
    "\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed: 183.9min remaining: 58.1min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed: 285.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid=[{'weights': ['uniform', 'distance']},\n",
       "                         {'n_neighbors': [3, 4, 5]}],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{\"weights\": ['uniform', 'distance'] }, {'n_neighbors': [3, 4, 5]}]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
    "grid_search.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716833333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W celu uzyskania macierzy pomyłek należy najpierw uzyskać zbiór prognoz, które porównamy z rzeczywistymi wartościami docelowymi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(knn_clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[5880    5    5    0    0    8   18    2    1    4]\n",
      " [   1 6709   10    0    3    1    2   13    1    2]\n",
      " [  46   55 5729   16    7    5   11   73   11    5]\n",
      " [   6   15   41 5924    0   60    4   32   27   22]\n",
      " [   6   47    2    1 5640    0   11    9    2  124]\n",
      " [  22    9    4   69   11 5212   53    5   10   26]\n",
      " [  22   14    0    0    4   20 5856    0    2    0]\n",
      " [   5   62   13    2   14    1    0 6106    2   60]\n",
      " [  21   74   33   75   38   82   22   14 5435   57]\n",
      " [  14   18    6   38   71   11    4   62    7 5718]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_train, y_train_pred)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97015"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "precision_score(y_train, y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97015"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97015"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "def shift_image(img, dx, dy):\n",
    "    img = img.reshape((28, 28))\n",
    "    new_img = shift(img, [dx, dy])\n",
    "    return new_img.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image shifted up')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train[1000]\n",
    "shifted_image_right = shift_image(image, 0, 5)\n",
    "shifted_image_up = shift_image(image, -5, 0)\n",
    "\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(figsize=(15,4), nrows=1, ncols=3);\n",
    "ax1.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "ax1.set_title(\"Original image\")\n",
    "ax2.imshow(shifted_image_right.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "ax2.set_title(\"Image shifted right\")\n",
    "ax3.imshow(shifted_image_up.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "ax3.set_title(\"Image shifted up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = [image for image in X_train]\n",
    "y_train_augmented = [label for label in y_train]\n",
    "\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    for image, label in zip(X_train, y_train):\n",
    "        X_train_augmented.append(shift_image(image, dx, dy))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx =np.random.permutation(len(X_train_augmented))\n",
    "\n",
    "X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "y_train_augmented = y_train_augmented[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#knn_clf = KNeighborsClassifier(**grid_search.best_params_)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to inherit from the correct class\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        # Define the correct function signature for on_epoch_end\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.90:\n",
    "                print(\"\\nReached 90% accuracy so cancelling training!\") \n",
    "                \n",
    "                # Stop training once the above condition is met\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4755 - accuracy: 0.8295\n",
      "Epoch 2/9\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3569 - accuracy: 0.8703\n",
      "Epoch 3/9\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3213 - accuracy: 0.8812\n",
      "Epoch 4/9\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2983 - accuracy: 0.8892\n",
      "Epoch 5/9\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2808 - accuracy: 0.8956\n",
      "Epoch 6/9\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.9010\n",
      "Reached 90% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2655 - accuracy: 0.9010\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the callback class\n",
    "callbacks = myCallback()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "]) \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# Fit the model for 10 epochs adding the callbacks\n",
    "# and save the training history\n",
    "history = model.fit(training_images, training_labels, epochs=9, callbacks=[callbacks])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Implement concept of Convolutional Neural Networks.\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([ \n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        \n",
    "    # Add the same layers as before\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax'),\n",
    "        ])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL TRAINING:\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.4472 - accuracy: 0.8380\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3008 - accuracy: 0.8893\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2527 - accuracy: 0.9065\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2203 - accuracy: 0.9182\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1944 - accuracy: 0.9270\n",
      "\n",
      "MODEL EVALUATION:\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2555 - accuracy: 0.9065\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "print(f'\\nMODEL TRAINING:')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluate on the test set\n",
    "print(f'\\nMODEL EVALUATION:')\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
      " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
      " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
